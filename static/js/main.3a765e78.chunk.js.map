{"version":3,"sources":["utils/drawCanvas.ts","components/App.tsx","reportWebVitals.ts","index.tsx"],"names":["drawPoint","ctx","point","x","canvas","width","y","height","fillStyle","beginPath","arc","Math","PI","fill","App","webcamRef","useRef","canvasRef","resultsRef","datas","useControls","bgImage","landmark","min","max","step","value","result","button","OutputData","results","current","console","log","multiFaceLandmarks","FACEMESH_LEFT_EYE","FACEMESH_RIGHT_EYE","FACEMESH_LIPS","onResults","useCallback","emphasis","save","clearRect","drawImage","image","tesselation","color","lineWidth","right_eye","left_eye","face_oval","landmarks","drawConnectors","FACEMESH_TESSELATION","FACEMESH_RIGHT_EYEBROW","FACEMESH_RIGHT_IRIS","FACEMESH_LEFT_EYEBROW","FACEMESH_LEFT_IRIS","FACEMESH_FACE_OVAL","restore","draw","getContext","useEffect","faceMesh","FaceMesh","locateFile","file","setOptions","maxNumFaces","refineLandmarks","minDetectionConfidence","minTrackingConfidence","camera","Camera","video","onFrame","a","send","start","close","className","styles","container","ref","style","visibility","audio","mirrored","screenshotFormat","videoConstraints","facingMode","css","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"iSA+DMA,EAAY,SAACC,EAA+BC,GACjD,IAAMC,EAAIF,EAAIG,OAAOC,MAAQH,EAAMC,EAC7BG,EAAIL,EAAIG,OAAOG,OAASL,EAAMI,EAGpCL,EAAIO,UAAY,UAChBP,EAAIQ,YACJR,EAAIS,IAAIP,EAAGG,EAJD,EAIO,EAAa,EAAVK,KAAKC,IAAQ,GACjCX,EAAIY,Q,OC7DQC,EAAU,WACtB,IAAMC,EAAYC,iBAAe,MAC3BC,EAAYD,iBAA0B,MACtCE,EAAaF,mBAGbG,EAAQC,YAAY,CACzBC,SAAS,EACTC,SAAU,CACTC,IAAK,EACLC,IAAK,IACLC,KAAM,EACNC,MAAO,GAERC,OAAQC,aAAO,WACdC,SAKIA,EAAa,WAClB,IAAMC,EAAUZ,EAAWa,QAC3BC,QAAQC,IAAIH,EAAQI,mBAAmB,IACvCF,QAAQC,IAAI,oBAAqBE,qBACjCH,QAAQC,IAAI,qBAAsBG,sBAClCJ,QAAQC,IAAI,gBAAiBI,kBAIxBC,EAAYC,uBACjB,SAACT,GAEAZ,EAAWa,QAAUD,ED5BJ,SACnB7B,EACA6B,EACAT,EACAmB,GAEA,IAAMnC,EAAQJ,EAAIG,OAAOC,MACnBE,EAASN,EAAIG,OAAOG,OAO1B,GALAN,EAAIwC,OACJxC,EAAIyC,UAAU,EAAG,EAAGrC,EAAOE,GAEvBc,GAASpB,EAAI0C,UAAUb,EAAQc,MAAO,EAAG,EAAGvC,EAAOE,GAEnDuB,EAAQI,mBAAoB,CAC/B,IAD+B,EAEzBW,EAAc,CAAEC,MAAO,YAAaC,UADxB,GAEZC,EAAY,CAAEF,MAAO,UAAWC,UAFpB,GAGZE,EAAW,CAAEH,MAAO,UAAWC,UAHnB,GAIZG,EAAY,CAAEJ,MAAO,UAAWC,UAJpB,GADa,cAOPjB,EAAQI,oBAPD,IAO/B,2BAAoD,CAAC,IAA1CiB,EAAyC,QAEnDC,yBAAenD,EAAKkD,EAAWE,uBAAsBR,GAErDO,yBAAenD,EAAKkD,EAAWf,qBAAoBY,GACnDI,yBAAenD,EAAKkD,EAAWG,yBAAwBN,GACvDI,yBAAenD,EAAKkD,EAAWI,sBAAqBP,GAEpDI,yBAAenD,EAAKkD,EAAWhB,oBAAmBc,GAClDG,yBAAenD,EAAKkD,EAAWK,wBAAuBP,GACtDG,yBAAenD,EAAKkD,EAAWM,qBAAoBR,GAEnDG,yBAAenD,EAAKkD,EAAWO,qBAAoBR,GAEnDE,yBAAenD,EAAKkD,EAAWd,gBAAea,GAG9ClD,EAAUC,EAAKkD,EAAUX,KAxBK,+BA2BhCvC,EAAI0D,UCVFC,CADY3C,EAAUc,QAAS8B,WAAW,MAChC/B,EAASX,EAAME,QAASF,EAAMG,YAEzC,CAACH,IAmCF,OAhCA2C,qBAAU,WACT,IAAMC,EAAW,IAAIC,WAAS,CAC7BC,WAAY,SAAAC,GACX,MAAM,qDAAN,OAA4DA,MAa9D,GATAH,EAASI,WAAW,CACnBC,YAAa,EACbC,iBAAiB,EACjBC,uBAAwB,GACxBC,sBAAuB,KAGxBR,EAASzB,UAAUA,GAEfvB,EAAUgB,QAAS,CACtB,IAAMyC,EAAS,IAAIC,SAAO1D,EAAUgB,QAAQ2C,MAAQ,CACnDC,QAAQ,WAAD,4BAAE,sBAAAC,EAAA,sEACFb,EAASc,KAAK,CAAEjC,MAAO7B,EAAUgB,QAAS2C,QADxC,2CAAF,kDAAC,GAGRrE,MAAO,KACPE,OAAQ,MAETiE,EAAOM,QAGR,OAAO,WACNf,EAASgB,WAER,CAACzC,IAGH,sBAAK0C,UAAWC,EAAOC,UAAvB,UAEC,cAAC,IAAD,CACCC,IAAKpE,EACLqE,MAAO,CAAEC,WAAY,UACrBC,OAAO,EACPjF,MAAO,KACPE,OAAQ,IACRgF,UAAQ,EACRC,iBAAiB,aACjBC,iBAAkB,CAAEpF,MAAO,KAAME,OAAQ,IAAKmF,WAAY,UAG3D,wBAAQP,IAAKlE,EAAW+D,UAAWC,EAAO7E,OAAQC,MAAO,KAAME,OAAQ,UAQpE0E,EAAS,CACdC,UAAWS,YAAF,iMASTvF,OAAQuF,YAAF,6JCpGQC,EAZS,SAACC,GACnBA,GAAeA,aAAuBC,UACxC,6BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCHdQ,IAASC,OACR,cAAC,IAAMC,WAAP,UACC,cAAC,EAAD,MAEDC,SAASC,eAAe,SAMzBb,M","file":"static/js/main.3a765e78.chunk.js","sourcesContent":["import { drawConnectors } from '@mediapipe/drawing_utils';\r\nimport {\r\n\tFACEMESH_FACE_OVAL, FACEMESH_LEFT_EYE, FACEMESH_LEFT_EYEBROW, FACEMESH_LEFT_IRIS, FACEMESH_LIPS,\r\n\tFACEMESH_RIGHT_EYE, FACEMESH_RIGHT_EYEBROW, FACEMESH_RIGHT_IRIS, FACEMESH_TESSELATION,\r\n\tNormalizedLandmark, Results\r\n} from '@mediapipe/face_mesh';\r\n\r\n/**\r\n * canvasに描画する\r\n * @param ctx コンテキスト\r\n * @param results 検出結果\r\n * @param bgImage capture imageを描画するか\r\n * @param emphasis 強調するlandmarkのindex\r\n */\r\nexport const draw = (\r\n\tctx: CanvasRenderingContext2D,\r\n\tresults: Results,\r\n\tbgImage: boolean,\r\n\temphasis: number\r\n) => {\r\n\tconst width = ctx.canvas.width\r\n\tconst height = ctx.canvas.height\r\n\r\n\tctx.save()\r\n\tctx.clearRect(0, 0, width, height)\r\n\r\n\tif (bgImage) ctx.drawImage(results.image, 0, 0, width, height)\r\n\r\n\tif (results.multiFaceLandmarks) {\r\n\t\tconst lineWidth = 1\r\n\t\tconst tesselation = { color: '#C0C0C070', lineWidth }\r\n\t\tconst right_eye = { color: '#FF3030', lineWidth }\r\n\t\tconst left_eye = { color: '#30FF30', lineWidth }\r\n\t\tconst face_oval = { color: '#E0E0E0', lineWidth }\r\n\r\n\t\tfor (const landmarks of results.multiFaceLandmarks) {\r\n\t\t\t// 顔の表面（埋め尽くし）\r\n\t\t\tdrawConnectors(ctx, landmarks, FACEMESH_TESSELATION, tesselation)\r\n\t\t\t// 右の目・眉・瞳\r\n\t\t\tdrawConnectors(ctx, landmarks, FACEMESH_RIGHT_EYE, right_eye)\r\n\t\t\tdrawConnectors(ctx, landmarks, FACEMESH_RIGHT_EYEBROW, right_eye)\r\n\t\t\tdrawConnectors(ctx, landmarks, FACEMESH_RIGHT_IRIS, right_eye)\r\n\t\t\t// 左の目・眉・瞳\r\n\t\t\tdrawConnectors(ctx, landmarks, FACEMESH_LEFT_EYE, left_eye)\r\n\t\t\tdrawConnectors(ctx, landmarks, FACEMESH_LEFT_EYEBROW, left_eye)\r\n\t\t\tdrawConnectors(ctx, landmarks, FACEMESH_LEFT_IRIS, left_eye)\r\n\t\t\t// 顔の輪郭\r\n\t\t\tdrawConnectors(ctx, landmarks, FACEMESH_FACE_OVAL, face_oval)\r\n\t\t\t// 唇\r\n\t\t\tdrawConnectors(ctx, landmarks, FACEMESH_LIPS, face_oval)\r\n\r\n\t\t\t// landmarkの強調描画\r\n\t\t\tdrawPoint(ctx, landmarks[emphasis])\r\n\t\t}\r\n\t}\r\n\tctx.restore()\r\n}\r\n\r\n/**\r\n * 特定のlandmarkを強調する\r\n * @param ctx\r\n * @param point\r\n */\r\nconst drawPoint = (ctx: CanvasRenderingContext2D, point: NormalizedLandmark) => {\r\n\tconst x = ctx.canvas.width * point.x\r\n\tconst y = ctx.canvas.height * point.y\r\n\tconst r = 5\r\n\r\n\tctx.fillStyle = '#22a7f2'\r\n\tctx.beginPath()\r\n\tctx.arc(x, y, r, 0, Math.PI * 2, true)\r\n\tctx.fill()\r\n}\r\n","import { button, useControls } from 'leva';\nimport React, { FC, useCallback, useEffect, useRef } from 'react';\nimport Webcam from 'react-webcam';\nimport { css } from '@emotion/css';\nimport { Camera } from '@mediapipe/camera_utils';\nimport {\n\tFaceMesh, FACEMESH_LEFT_EYE, FACEMESH_LIPS, FACEMESH_RIGHT_EYE, Results\n} from '@mediapipe/face_mesh';\nimport { draw } from '../utils/drawCanvas';\n\nexport const App: FC = () => {\n\tconst webcamRef = useRef<Webcam>(null)\n\tconst canvasRef = useRef<HTMLCanvasElement>(null)\n\tconst resultsRef = useRef<Results>()\n\n\t// コントローラーの追加\n\tconst datas = useControls({\n\t\tbgImage: false,\n\t\tlandmark: {\n\t\t\tmin: 0,\n\t\t\tmax: 477,\n\t\t\tstep: 1,\n\t\t\tvalue: 0\n\t\t},\n\t\tresult: button(() => {\n\t\t\tOutputData()\n\t\t})\n\t})\n\n\t/** 検出結果をconsoleに出力する */\n\tconst OutputData = () => {\n\t\tconst results = resultsRef.current!\n\t\tconsole.log(results.multiFaceLandmarks[0])\n\t\tconsole.log('FACEMESH_LEFT_EYE', FACEMESH_LEFT_EYE)\n\t\tconsole.log('FACEMESH_RIGHT_EYE', FACEMESH_RIGHT_EYE)\n\t\tconsole.log('FACEMESH_LIPS', FACEMESH_LIPS)\n\t}\n\n\t/** 検出結果（フレーム毎に呼び出される） */\n\tconst onResults = useCallback(\n\t\t(results: Results) => {\n\t\t\t// 検出結果の格納\n\t\t\tresultsRef.current = results\n\t\t\t// 描画処理\n\t\t\tconst ctx = canvasRef.current!.getContext('2d')!\n\t\t\tdraw(ctx, results, datas.bgImage, datas.landmark)\n\t\t},\n\t\t[datas]\n\t)\n\n\tuseEffect(() => {\n\t\tconst faceMesh = new FaceMesh({\n\t\t\tlocateFile: file => {\n\t\t\t\treturn `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`\n\t\t\t}\n\t\t})\n\n\t\tfaceMesh.setOptions({\n\t\t\tmaxNumFaces: 1,\n\t\t\trefineLandmarks: true, // landmarks 468 -> 478\n\t\t\tminDetectionConfidence: 0.5,\n\t\t\tminTrackingConfidence: 0.5\n\t\t})\n\n\t\tfaceMesh.onResults(onResults)\n\n\t\tif (webcamRef.current) {\n\t\t\tconst camera = new Camera(webcamRef.current.video!, {\n\t\t\t\tonFrame: async () => {\n\t\t\t\t\tawait faceMesh.send({ image: webcamRef.current!.video! })\n\t\t\t\t},\n\t\t\t\twidth: 1280,\n\t\t\t\theight: 720\n\t\t\t})\n\t\t\tcamera.start()\n\t\t}\n\n\t\treturn () => {\n\t\t\tfaceMesh.close()\n\t\t}\n\t}, [onResults])\n\n\treturn (\n\t\t<div className={styles.container}>\n\t\t\t{/* capture */}\n\t\t\t<Webcam\n\t\t\t\tref={webcamRef}\n\t\t\t\tstyle={{ visibility: 'hidden' }}\n\t\t\t\taudio={false}\n\t\t\t\twidth={1280}\n\t\t\t\theight={720}\n\t\t\t\tmirrored\n\t\t\t\tscreenshotFormat=\"image/jpeg\"\n\t\t\t\tvideoConstraints={{ width: 1280, height: 720, facingMode: 'user' }}\n\t\t\t/>\n\t\t\t{/* draw */}\n\t\t\t<canvas ref={canvasRef} className={styles.canvas} width={1280} height={720} />\n\t\t</div>\n\t)\n}\n\n// ==============================================\n// styles\n\nconst styles = {\n\tcontainer: css`\n\t\tposition: relative;\n\t\twidth: 100vw;\n\t\theight: 100vh;\n\t\toverflow: hidden;\n\t\tdisplay: flex;\n\t\tjustify-content: center;\n\t\talign-items: center;\n\t`,\n\tcanvas: css`\n\t\tposition: absolute;\n\t\twidth: 1280px;\n\t\theight: 720px;\n\t\tbackground-color: #1e1e1e;\n\t\tborder: 1px solid #fff;\n\t`\n}\n","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import './index.css';\nimport React from 'react';\nimport ReactDOM from 'react-dom';\nimport { App } from './components/App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n\t<React.StrictMode>\n\t\t<App />\n\t</React.StrictMode>,\n\tdocument.getElementById('root')\n)\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals()\n"],"sourceRoot":""}